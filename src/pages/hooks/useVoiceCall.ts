// src/pages/hooks/useVoiceCall.ts
import { useState, useCallback, useRef, useEffect } from 'react'
import { socketService } from '../../service/socketService'
import { voiceService } from '../../service/interview/voiceService'
import { AIResponse } from '../../types'

export const useVoiceCall = (sessionId: string, position: string) => {
  const [isRecording, setIsRecording] = useState<boolean>(false)
  const [transcript, setTranscript] = useState('')
  const [aiResponse, setAiResponse] = useState('')
  const [isAIThinking, setIsAIThinking] = useState(false)
  const [isAISpeaking, setIsAISpeaking] = useState(false)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const [error, setError] = useState<string | null>(null)
  const recognitionRestartAttemptsRef = useRef(0) // Ð¡Ñ‡ÐµÑ‚Ñ‡Ð¸Ðº Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°

  const fullCleanup = useCallback(() => {
    console.log('ðŸ§¹ Performing full cleanup of voice call...')

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) {
        console.log('Recognition already stopped')
      }
      recognitionRef.current = null
    }

    voiceService.stopAudio().catch(console.error)
    socketService.disconnect()

    setIsRecording(false)
    setIsAIThinking(false)
    setIsAISpeaking(false)
    setTranscript('')
    setAiResponse('')
    setError(null)
    recognitionRestartAttemptsRef.current = 0
  }, [])

  useEffect(() => {
    const handleAIResponse = async (data: AIResponse) => {
      console.log('ðŸ¤– AI Response received:', data.text)
      if (data.text) {
        setAiResponse(data.text)
        setIsAIThinking(false)
        setError(null)

        setIsAISpeaking(true)
        try {
          console.log('ðŸŽµ Playing AI audio...')
          await voiceService.playAssistantResponse(data.text)
          console.log('âœ… AI finished speaking')

          // Ð£Ð’Ð•Ð›Ð˜Ð§Ð˜Ð’ÐÐ•Ðœ Ð—ÐÐ”Ð•Ð Ð–ÐšÐ£ ÐŸÐ•Ð Ð•Ð” Ð—ÐÐŸÐ£Ð¡ÐšÐžÐœ Ð—ÐÐŸÐ˜Ð¡Ð˜
          setTimeout(() => {
            if (!isRecording) {
              console.log('ðŸŽ¤ Starting recording after AI response')
              startRecording()
            }
          }, 1000) // Ð‘Ñ‹Ð»Ð¾ 500, ÑÑ‚Ð°Ð»Ð¾ 1500 Ð¼Ñ
        } catch (error) {
          console.error('âŒ Error playing AI audio:', error)
          setTimeout(() => {
            if (!isRecording) {
              startRecording()
            }
          }, 2000)
        } finally {
          setIsAISpeaking(false)
        }
      }
    }

    const handleAIError = (errorMsg: string) => {
      console.error('AI Error in useVoiceCall:', errorMsg)
      setError(errorMsg)
      setIsAIThinking(false)
      setIsAISpeaking(false)

      setTimeout(() => {
        if (!isRecording) {
          startRecording()
        }
      }, 2000)
    }

    console.log(`ðŸŽ¯ Initializing voice call: session=${sessionId}, position=${position}`)

    socketService.connect(sessionId, position)
    socketService.onMessage(handleAIResponse)
    socketService.onError(handleAIError)

    // Ð£Ð’Ð•Ð›Ð˜Ð§Ð˜Ð’ÐÐ•Ðœ ÐÐÐ§ÐÐ›Ð¬ÐÐ£Ð® Ð—ÐÐ”Ð•Ð Ð–ÐšÐ£
    const timer = setTimeout(() => {
      console.log('ðŸŽ¤ Starting initial recording...')
      startRecording()
    }, 2000) // Ð‘Ñ‹Ð»Ð¾ 1000, ÑÑ‚Ð°Ð»Ð¾ 2000 Ð¼Ñ

    return () => {
      console.log('ðŸ”´ useVoiceCall unmounting - cleaning up...')
      clearTimeout(timer)
      socketService.offMessage()
      socketService.offError()
      fullCleanup()
    }
  }, [sessionId, position, fullCleanup])

  const startRecording = useCallback(async () => {
    if (isRecording) {
      console.log('Recording already started')
      return
    }

    if (isAISpeaking || isAIThinking) {
      console.log('â³ Cannot start recording - AI is speaking or thinking')
      return
    }

    const SpeechRecognitionImpl = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognitionImpl) {
      console.error('Speech Recognition API is not supported in this browser.')
      return
    }

    // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
    if (recognitionRef.current) {
      recognitionRef.current.stop()
    }

    const recognition = new SpeechRecognitionImpl()
    recognition.lang = 'ru-RU'
    recognition.continuous = false
    recognition.interimResults = true
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      console.log('ðŸŽ¤ Speech recognition started, waiting for speech...')
    }

    // Ð”ÐžÐ‘ÐÐ’Ð›Ð¯Ð•Ðœ: Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸
    if (recognition.continuous === undefined) {
      // Ð”Ð»Ñ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð¾Ð² ÑƒÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ñ‹
      recognition.onstart = () => {
        console.log('ðŸŽ¤ Speech recognition started, waiting for speech...')
      }
    }

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const last = event.results.length - 1
      const text = event.results[last][0].transcript.trim()
      setTranscript(text)

      if (event.results[last].isFinal) {
        console.log('ðŸŽ¯ Final transcript:', text)
        setIsAIThinking(true)
        recognitionRestartAttemptsRef.current = 0 // Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸

        const success = socketService.sendTranscript(sessionId, text, position)
        if (success) {
          stopRecording()
        } else {
          console.error('Failed to send transcript, keeping recording active')
          setIsAIThinking(false)
        }
      }
    }

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error)

      if (event.error === 'no-speech') {
        console.log('No speech detected - increasing restart delay')
        recognitionRestartAttemptsRef.current++

        // Ð£Ð’Ð•Ð›Ð˜Ð§Ð˜Ð’ÐÐ•Ðœ Ð—ÐÐ”Ð•Ð Ð–ÐšÐ£ ÐŸÐ•Ð Ð•Ð” ÐŸÐ•Ð Ð•Ð—ÐÐŸÐ£Ð¡ÐšÐžÐœ ÐŸÐ Ð˜ no-speech
        const delay = Math.min(1000 * recognitionRestartAttemptsRef.current, 5000)
        console.log(`ðŸ”„ Restarting recognition in ${delay}ms (attempt ${recognitionRestartAttemptsRef.current})`)

        setTimeout(() => {
          if (isRecording && !isAIThinking && !isAISpeaking) {
            try {
              recognition.start()
            } catch (error) {
              console.error('Error restarting recognition:', error)
            }
          }
        }, delay)
        return
      }

      if (event.error === 'aborted') {
        console.log('Recognition aborted - normal when stopping')
        return
      }

      setIsRecording(false)
    }

    recognition.onend = () => {
      console.log('Recognition ended')

      // Ð£Ð’Ð•Ð›Ð˜Ð§Ð˜Ð’ÐÐ•Ðœ Ð‘ÐÐ—ÐžÐ’Ð£Ð® Ð—ÐÐ”Ð•Ð Ð–ÐšÐ£ ÐŸÐ•Ð Ð•Ð—ÐÐŸÐ£Ð¡ÐšÐ
      if (isRecording && !isAIThinking && !isAISpeaking) {
        const baseDelay = 2000 // Ð‘Ñ‹Ð»Ð¾ 500, ÑÑ‚Ð°Ð»Ð¾ 2000 Ð¼Ñ
        const attemptDelay = Math.min(baseDelay * (recognitionRestartAttemptsRef.current + 1), 10000)

        console.log(`ðŸ”„ Restarting recognition in ${attemptDelay}ms`)
        setTimeout(() => {
          if (isRecording && !isAIThinking && !isAISpeaking) {
            try {
              recognition.start()
            } catch (error) {
              console.error('Error restarting recognition:', error)
            }
          }
        }, attemptDelay)
      }
    }

    try {
      recognition.start()
      recognitionRef.current = recognition
      setIsRecording(true)
      recognitionRestartAttemptsRef.current = 0 // Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ
      console.log('ðŸŽ¤ Recording started - waiting for user speech...')
    } catch (error) {
      console.error('Error starting recognition:', error)
    }
  }, [sessionId, position, isRecording, isAIThinking, isAISpeaking])

  const stopRecording = useCallback(() => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (error) {
        console.log('Error stopping recognition:', error)
      }
      recognitionRef.current = null
    }
    setIsRecording(false)
    console.log('â¹ï¸ Recording stopped')
  }, [])

  const toggleRecording = useCallback(() => {
    if (isRecording) {
      stopRecording()
    } else {
      startRecording()
    }
  }, [isRecording, startRecording, stopRecording])

  return {
    isRecording,
    isAIThinking,
    isAISpeaking,
    startRecording,
    stopRecording,
    toggleRecording,
    transcript,
    aiResponse,
    error
  }
}