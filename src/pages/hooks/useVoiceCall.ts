// src/pages/hooks/useVoiceCall.ts
import { useState, useCallback, useRef, useEffect } from 'react'
import { socketService } from '../../service/socketService'
import { voiceService } from '../../service/interview/voiceService'
import { AIResponse } from '../../types'

export const useVoiceCall = (sessionId: string, position: string) => {
  const [isRecording, setIsRecording] = useState<boolean>(false)
  const [transcript, setTranscript] = useState('')
  const [aiResponse, setAiResponse] = useState('')
  const [isAIThinking, setIsAIThinking] = useState(false)
  const [isAISpeaking, setIsAISpeaking] = useState(false)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const [error, setError] = useState<string | null>(null)
  const recognitionRestartAttemptsRef = useRef(0) // –°—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
  const startRecordingRef = useRef<(() => Promise<void>) | null>(null) // Ref –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ startRecording
  const positionRef = useRef(position) // Ref –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

  const fullCleanup = useCallback(() => {
    console.log('üßπ Performing full cleanup of voice call...')

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) {
        console.log(`Recognition already stopped: ${e}`)
      }
      recognitionRef.current = null
    }

    voiceService.stopAudio().catch(console.error)
    //socketService.disconnect()

    setIsRecording(false)
    setIsAIThinking(false)
    setIsAISpeaking(false)
    setTranscript('')
    setAiResponse('')
    setError(null)
    recognitionRestartAttemptsRef.current = 0
  }, [])

  useEffect(() => {
    // –ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º, –µ—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    if (!position || !sessionId) {
      console.log(`‚è≥ Waiting for position to load: session=${sessionId}, position=${position}`)
      return
    }

    const handleAIResponse = async (data: AIResponse) => {
      console.log('ü§ñ AI Response received:', data.text)
      if (data.text) {
        setAiResponse(data.text)
        setIsAIThinking(false)
        setError(null)

        setIsAISpeaking(true)
        try {
          console.log('üéµ Playing AI audio...')
          await voiceService.playAssistantResponse(data.text)
          console.log('‚úÖ AI finished speaking')

          // –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú –ó–ê–î–ï–†–ñ–ö–£ –ü–ï–†–ï–î –ó–ê–ü–£–°–ö–û–ú –ó–ê–ü–ò–°–ò
          setTimeout(() => {
            if (!isRecording && startRecordingRef.current) {
              console.log('üé§ Starting recording after AI response')
              startRecordingRef.current()
            }
          }, 800) // –ë—ã–ª–æ 500, —Å—Ç–∞–ª–æ 1500 –º—Å
        } catch (error) {
          console.error('‚ùå Error playing AI audio:', error)
          setTimeout(() => {
            if (!isRecording && startRecordingRef.current) {
              startRecordingRef.current()
            }
          }, 2000)
        } finally {
          setIsAISpeaking(false)
        }
      }
    }

    const handleAIError = (errorMsg: string) => {
      console.error('AI Error in useVoiceCall:', errorMsg)
      setError(errorMsg)
      setIsAIThinking(false)
      setIsAISpeaking(false)

      setTimeout(() => {
        if (!isRecording && startRecordingRef.current) {
          startRecordingRef.current().then()
        }
      }, 2000)
    }

    console.log(`üéØ Initializing voice call: session=${sessionId}, position=${position}`)

    // –û–±–Ω–æ–≤–ª—è–µ–º ref –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏
    positionRef.current = position

    socketService.connect(sessionId, position).then()
    socketService.onMessage(handleAIResponse)
    socketService.onError(handleAIError)

    // –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú –ù–ê–ß–ê–õ–¨–ù–£–Æ –ó–ê–î–ï–†–ñ–ö–£
    const timer = setTimeout(() => {
      console.log('üé§ Starting initial recording...')
      if (startRecordingRef.current) {
        startRecordingRef.current().then()
      }
    }, 2000)

    return () => {
      console.log('üî¥ useVoiceCall unmounting - cleaning up...')
      clearTimeout(timer)
      socketService.offMessage()
      socketService.offError()
      fullCleanup()
    }
  }, [sessionId, position, fullCleanup]) // –î–æ–±–∞–≤–∏–ª–∏ position –æ–±—Ä–∞—Ç–Ω–æ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

  const stopRecording = useCallback(() => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (error) {
        console.log('Error stopping recognition:', error)
      }
      recognitionRef.current = null
    }
    setIsRecording(false)
    console.warn('‚èπÔ∏è Recording stopped')
  }, [])

  const startRecording = useCallback(async () => {
    if (isRecording) {
      console.log('Recording already started')
      return
    }

    if (isAISpeaking || isAIThinking) {
      console.log('‚è≥ Cannot start recording - AI is speaking or thinking')
      return
    }

    const SpeechRecognitionImpl = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognitionImpl) {
      console.error('Speech Recognition API is not supported in this browser.')
      setError('Speech Recognition API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ')
      return
    }

    console.log('‚úÖ Speech Recognition API available')

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
    if (recognitionRef.current) {
      recognitionRef.current.stop()
    }

    // SpeechRecognition —Å–∞–º –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
    // –ù–ï –Ω—É–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å getUserMedia - —ç—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç!
    const recognition = new SpeechRecognitionImpl()
    recognition.lang = 'ru-RU'
    recognition.continuous = false  // –ö–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ
    recognition.interimResults = true
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      console.log('üé§ Speech recognition started, waiting for speech...')
    }

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const last = event.results.length - 1
      const text = event.results[last][0].transcript.trim()
      setTranscript(text)

      if (event.results[last].isFinal) {
        console.log('üéØ Final transcript:', text)
        setIsAIThinking(true)
        recognitionRestartAttemptsRef.current = 0 // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –∏–∑ ref
        const success = socketService.sendTranscript(sessionId, text, positionRef.current)
        if (success) {
          stopRecording()
        } else {
          console.error('Failed to send transcript, keeping recording active')
          setIsAIThinking(false)
        }
      }
    }

    recognition.onerror = (event: any) => {
      console.error('‚ùå Speech recognition error:', event.error, event)

      // –û—à–∏–±–∫–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
        console.error('üö´ Microphone access denied in Speech Recognition')
        setError('–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±—Ä–∞—É–∑–µ—Ä–∞.')
        setIsRecording(false)
        return
      }

      // –û—à–∏–±–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      if (event.error === 'no-speech') {
        console.log('üîá No speech detected - increasing restart delay')
        recognitionRestartAttemptsRef.current++

        // –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú –ó–ê–î–ï–†–ñ–ö–£ –ü–ï–†–ï–î –ü–ï–†–ï–ó–ê–ü–£–°–ö–û–ú –ü–†–ò no-speech
        const delay = Math.min(1000 * recognitionRestartAttemptsRef.current, 5000)
        console.log(`üîÑ Restarting recognition in ${delay}ms (attempt ${recognitionRestartAttemptsRef.current})`)

        setTimeout(() => {
          if (isRecording && !isAIThinking && !isAISpeaking) {
            try {
              // –ò—Å–ø–æ–ª—å–∑—É–µ–º recognition –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∑–∞–º—ã–∫–∞–Ω–∏—è, –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ
              recognition.start()
            } catch (error) {
              console.error('Error restarting recognition:', error)
            }
          }
        }, delay)
        return
      }

      // –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
      if (event.error === 'network') {
        console.warn('üåê Network error in speech recognition - will retry')
        recognitionRestartAttemptsRef.current++
        
        const delay = Math.min(2000 * recognitionRestartAttemptsRef.current, 10000)
        console.log(`üîÑ Retrying recognition after network error in ${delay}ms (attempt ${recognitionRestartAttemptsRef.current})`)
        
        setTimeout(() => {
          if (isRecording && !isAIThinking && !isAISpeaking) {
            try {
              // –ò—Å–ø–æ–ª—å–∑—É–µ–º recognition –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∑–∞–º—ã–∫–∞–Ω–∏—è, –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ
              recognition.start()
              console.log('üîÑ Recognition restarted after network error')
            } catch (error) {
              console.error('‚ùå Error restarting recognition after network error:', error)
            }
          }
        }, delay)
        return
      }

      // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
      if (event.error === 'aborted') {
        console.log('‚èπÔ∏è Recognition aborted - normal when stopping')
        return
      }

      // –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏
      console.error('‚ùå Unhandled recognition error:', event.error)
      setError(`–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: ${event.error}`)
      setIsRecording(false)
    }

    recognition.onend = () => {
      console.log('Recognition ended')

      // –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú –ë–ê–ó–û–í–£–Æ –ó–ê–î–ï–†–ñ–ö–£ –ü–ï–†–ï–ó–ê–ü–£–°–ö–ê
      // –í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º recognition –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∑–∞–º—ã–∫–∞–Ω–∏—è, –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ
      if (isRecording && !isAIThinking && !isAISpeaking) {
        const baseDelay = 2000 // –ë—ã–ª–æ 500, —Å—Ç–∞–ª–æ 2000 –º—Å
        const attemptDelay = Math.min(baseDelay * (recognitionRestartAttemptsRef.current + 1), 10000)

        console.log(`üîÑ Restarting recognition in ${attemptDelay}ms`)
        setTimeout(() => {
          if (isRecording && !isAIThinking && !isAISpeaking) {
            try {
              // –ò—Å–ø–æ–ª—å–∑—É–µ–º recognition –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∑–∞–º—ã–∫–∞–Ω–∏—è, –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ
              recognition.start()
              console.log('üé§ Recognition restarted successfully')
            } catch (error) {
              console.error('Error restarting recognition:', error)
            }
          }
        }, attemptDelay)
      } else {
        // –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–ø–∏—Å–∏
        setIsRecording(false)
      }
    }

    try {
      console.log('üöÄ Attempting to start speech recognition...')
      console.log('üîç Recognition object:', {
        lang: recognition.lang,
        continuous: recognition.continuous,
        interimResults: recognition.interimResults,
        serviceURI: (recognition as any).serviceURI || 'default'
      })
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º—ã –Ω–∞ HTTPS –∏–ª–∏ localhost (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ SpeechRecognition)
      const isSecure = window.location.protocol === 'https:' || window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1'
      if (!isSecure) {
        console.warn('‚ö†Ô∏è SpeechRecognition requires HTTPS or localhost. Current protocol:', window.location.protocol)
        setError('SpeechRecognition —Ç—Ä–µ–±—É–µ—Ç HTTPS —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ localhost')
      }
      
      recognition.start()
      recognitionRef.current = recognition
      setIsRecording(true)
      recognitionRestartAttemptsRef.current = 0 // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–ø—É—Å–∫–µ
      console.log('üé§ Recording started - waiting for user speech...')
      setError(null) // –û—á–∏—â–∞–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–ø—É—Å–∫–µ
    } catch (error) {
      console.error('‚ùå Error starting recognition:', error)
      console.error('‚ùå Error details:', {
        name: error?.name,
        message: error?.message,
        stack: error?.stack
      })
      setError(`–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: ${error.message || '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}`)
    }
  }, [sessionId, position, isRecording, isAIThinking, isAISpeaking, stopRecording])

  // –û–±–Ω–æ–≤–ª—è–µ–º ref –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏
  useEffect(() => {
    startRecordingRef.current = startRecording
  }, [startRecording])

  // –û–±–Ω–æ–≤–ª—è–µ–º positionRef –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø–æ–∑–∏—Ü–∏–∏
  useEffect(() => {
    positionRef.current = position
  }, [position])

  const toggleRecording = useCallback(() => {
    if (isRecording) {
      stopRecording()
    } else {
      startRecording().then()
    }
  }, [isRecording, startRecording, stopRecording])

  return {
    isRecording,
    isAIThinking,
    isAISpeaking,
    startRecording,
    stopRecording,
    toggleRecording,
    transcript,
    aiResponse,
    error
  }
}